import os
import random
from openai import OpenAI
import string
import nltk
import sys
import uuid
import __main__ as main

# Set your OpenAI API key (or any other LLM provider's key)
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

# juno : for testing purposes
if not OPENAI_KEY and os.path.exists('/mnt/c/Users/juno/Desktop/llmstuff/secretkey'):
    with open('/mnt/c/Users/juno/Desktop/llmstuff/secretkey', 'r') as f:
        OPENAI_KEY = f.read().strip()
        OpenAI.api_key = OPENAI_KEY

client = OpenAI(api_key=OPENAI_KEY)

# Define the rule templates for each rule type.
rule_templates = {
    "attribute_based": "Generate a rule based on a single object attribute like color, size, or shape.",
    "categorical": "Generate a rule based on a specific category of objects.",
    "relational": "Generate a rule based on a relational attribute between objects (e.g., size, weight).",
    "logical": "Generate a rule that combines two attributes using logical conditions like AND or OR.",
    "semantic": "Generate a rule that involves objects related by their use or context (e.g., used in a kitchen)."
}

# Dictionary to store rules under each rule type
rules_storage = {
    "attribute_based": [],
    "categorical": [],
    "relational": [],
    "logical": [],
    "semantic": []
}

# Function to send a prompt to the LLM and get the response
def get_llm_response(prompt, sysprompt=None):
    response = client.chat.completions.create(model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": sysprompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7)
    return response.choices[0].message.content.strip()

## Function to generate a rule prompt for each rule type
def generate_rule_prompt(rule_type):
    template_prompt = rule_templates[rule_type]
    return template_prompt

## Function to collect and process the LLM outputs from the rule prompt
def generate_rule_with_llm(rule_type):
    # Generate the template prompt based on the rule type
    prompt = generate_rule_prompt(rule_type)
    
    # Call the LLM with the prompt to generate a specific rule
    llm_response = get_llm_response(prompt)
    
    # Process and return the rule generated by the LLM
    return llm_response

## Function to generate and store the rule under the correct rule type
def generate_and_store_rule():
    # Randomly select a rule type
    rule_type = random.choice(list(rule_templates.keys()))
    
    # Get the specific rule from the LLM based on the rule type
    rule = generate_rule_with_llm(rule_type)
    
    # Store the rule in the correct category within rules_storage
    rules_storage[rule_type].append(rule)
    
    print(f"Generated rule type: {rule_type}")
    print(f"Rule: {rule}")
    
    return rule_type, rule

def get_std_corpus():
        try:
            words = set(nltk.corpus.words.words())
        except LookupError:
            nltk.download('words')
            words = set(nltk.corpus.words.words())
        return words

def read_promptstring(filename):
    with open(os.path.join('promptstrings', filename), 'r') as f:
        promptstring = f.read()
    return promptstring

class GuessingGame:

    def __init__(self, rngstate, domain=None, difficulty=None, init_examples=None, use_llm=False):
        self.rngstate = rngstate
        self.domain = domain
        self.difficulty = difficulty
        self.init_examples = init_examples
        self.use_llm = use_llm

        self.wordgen_fn = self.make_word_generator(k=5, is_using_corpus=True)
        genrule = self.generate_rule_chatgpt if self.use_llm else self.generate_rule
        self.rule_code, self.rule_fn = genrule()
        
    def generate_rule_chatgpt(self):
        random.setstate(self.rngstate)  # unused
        prompt = "Generate a rule based on the following criteria:\n"
        if self.domain:
            prompt += f"Domain: {self.domain}\n"
        if self.difficulty:
            prompt += f"Difficulty: {self.difficulty}\n"
        if self.init_examples:
            prompt += f"Examples: {self.init_examples}\n\n"
        
        prompt += "Generated code:"

        sysprompt = read_promptstring('sysprompt.txt')
        ans = get_llm_response(prompt=prompt, sysprompt=sysprompt)
        ans_strip = ''
        for line in ans.splitlines():
            if not line.startswith('```'):
                ans_strip += line + '\n'
        print(ans_strip)
        generated_fn = None
        try:
            local_namespace = {}
            print('debug')
            print(ans_strip)
            exec(ans_strip, globals(), local_namespace)
            if 'generated_fn' in local_namespace:
                generated_fn = local_namespace['generated_fn']
            else:
                raise Exception('problem assigning "generated_fn"') 
        except SyntaxError as e:
            print("Syntax Error in Generated Code:", e)
            return
        # print(generated_fn)
        self.rngstate = random.getstate()
        return ans_strip, generated_fn

    def word_generator(self, minL=0, maxL=float('inf')):
        random.setstate(self.rngstate)
        k = random.choice(range(minL, maxL))
        word = ''.join(random.choice(string.ascii_lowercase) for _ in range(k))
        self.rngstate = random.getstate()
        return word

    def word_generator_from_corpus(self, minL=0, maxL=float('inf'), corpus=None):
        if corpus is None:
            words = get_std_corpus()
        else:
            words = corpus
        valid_words = [word.lower() for word in words 
                    if minL <= len(word) < maxL]
        if not valid_words:
            raise ValueError(f"No words found with length between {minL} and {maxL}")
        random.setstate(self.rngstate)
        word = random.choice(valid_words)
        self.rngstate = random.getstate()
        return word

    def make_word_generator(self, k, is_using_corpus=False):
        if is_using_corpus:
            return lambda: self.word_generator_from_corpus(minL=4, maxL=8, corpus=None)
        return lambda: self.word_generator(k)

    def generate_rule(self):
        def has_at_least_two_vowels(x: string):
            return sum([c in 'aeiou' for c in x]) >= 2
        def has_less_than_two_vowels(x: string):
            return not has_at_least_two_vowels(x)
        def starts_with_first_half_alphabet(x: string):
            return ord(x[0]) - ord('a') < 13
        random.setstate(self.rngstate)
        fn = random.choice([has_at_least_two_vowels, has_less_than_two_vowels, starts_with_first_half_alphabet])
        self.rngstate = random.getstate()
        return 'dummy', fn

    def generate_example(self):
        random_word = self.wordgen_fn()
        return random_word, self.rule_fn(random_word)
    
    def validate_guess(self, guess):  # llm to validate guess
        sysprompt = read_promptstring('validate_sysprompt.txt')
        prompt = 'Function code:\n'
        prompt += self.rule_code
        prompt += '\n\n'
        prompt += 'Guess:\n'
        prompt += guess
        ans = get_llm_response(prompt=prompt, sysprompt=sysprompt)
        ans = ans.strip()
        print('debug: ' + ans)
        ans_last = ans.split()[-1]
        print('debug: ' + ans_last)
        if ans_last not in ['YES', 'NO']:
            print('invalid LLM output')
            raise Exception
        return ans_last == 'YES'



# client level API (serverside responses to client requests)
game_dct = {}
def request_game_instance(domain=None, difficulty=None, init_examples=None, use_llm=False):
    rngstate = random.Random()
    if not init_examples:
        init_examples = read_promptstring('init_examples_std_lexical_fns.txt')
    game = GuessingGame(random.getstate(), domain=None, difficulty=None,
                         init_examples=None, use_llm=False)
    game_id = uuid.uuid4()
    game_dct[game_id] = game
    return game_id

def request_more_examples(game_id, n_examples=5):
    if game_id not in game_dct:
        raise Exception('Invalid game id!')
    print('sdfsdfsdf', game_id)
    game = game_dct[game_id]
    exs = []
    for _ in range(n_examples):
        exs.append(game.generate_example())
    return exs

def request_guess_validation(game_id, guess):
    game = game_dct[game_id]
    return game.validate_guess(guess)


# Main loop to generate and display a set of rules, and store them

def main():
    init_examples_std_lexical_fns = read_promptstring('init_examples_std_lexical_fns.txt')

    print('Lexical style rules (string manipulation)')
    print('5 random game instances (hardcoded rule fns)')
    for i in range(5):
        print(f'Game {i}')
        random.seed(42 + i)
        game = GuessingGame(random.getstate(), init_examples=init_examples_std_lexical_fns)
        print(f'DEBUG: secret rule is: {game.rule_fn.__name__}')
        for _ in range(10):
            random_word, is_rule_true = game.generate_example()
            print(random_word, is_rule_true)
    print('5 LLM-generated rules (standard English corpus)')
    for i in range(5):
        print(f'Game {i}')
        random.seed(42 + i)
        game = GuessingGame(random.getstate(), init_examples=init_examples_std_lexical_fns,
            use_llm=True)
        print(f'DEBUG: secret rule is: {game.rule_fn.__name__}')
        for _ in range(10):
            random_word, is_rule_true = game.generate_example()
            print(random_word, is_rule_true)

if __name__ == "__main__":
    if sys.flags.interactive:
        print('Interactive mode')
        print('Help (Function Signatures):')
        print('------------------------------')
        print('request_game_instance(domain=None, difficulty=None, init_examples=None, use_llm=False)')
        print('request_more_examples(game_id)')
        print('request_guess_validation(game_id, guess)')
        init_examples_std_lexical_fns = read_promptstring('init_examples_std_lexical_fns.txt')
        print('------------------------------')
        game = GuessingGame(random.getstate(), init_examples=init_examples_std_lexical_fns,
            use_llm=True)
        pass
    else:
        main()